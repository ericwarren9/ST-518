---
title: "ST 518 Homework 1"
author: "Eric Warren"
date: "`r Sys.Date()`"
urlcolor: blue
---

```{r output setup, eval=FALSE, echo=FALSE}
# This code allows us to render a pdf document
rmarkdown::render("~/ST-518/Warren_ST 518 HW 1.Rmd", 
              output_format = "pdf_document", 
              output_options = list(
                toc = TRUE, 
                toc_depth = 3,
                number_sections = TRUE,
                df_print = "tibble"
                )
              )
```

# Problem 1

```{r options, include=FALSE}
library(tidyverse)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

Read in the data to use for the problem
```{r problem 1 read in}
library(tidyverse)
heights <- read_table("~/ST-518/heights-tall.txt")
heights
```

We can see this data has 928 rows with two columns. The rows represent the observation of the parent's height represents the first column and the son's height represents the second column. Height seems to be in inches.

## Part A

Consider the population from which this simple random sample of adult males was drawn. Let $\mu$ denote the mean of the population. Use statistical software to compute $\bar{y}$ as an estimate of $\mu$. Obtain a 95% confidence interval for $\mu$. If another person is sampled at random, would you expect this interval to capture this personâ€™s height with high confidence?

Since we are trying to look at y variable, we are going to find the mean of the `son` column and we are going to make a 95% confidence interval of this variable.
```{r problem 1 part a-1}
library(stats)
# Find the mean of adult heights
y_bar <- mean(heights$son)
y_bar
# Find the confidence interval
confidence_adult <- t.test(heights$son, conf.level = 0.95)
confidence_adult$conf.int[1] # Lower confidence value
confidence_adult$conf.int[2] # Upper confidence value
```

Here we can see that the $\bar{y}$ = `r y_bar` inches. We are also 95% confident that the true average height of adult men is between `r confidence_adult$conf.int[1]` and `r confidence_adult$conf.int[2]` inches. Despite obtaining this interval, this does not mean that adding another observation will be within this amount will occur 95% of the time. We are saying that we believe that 95 out of 100 samples taken the same way as this one will occur the true population mean. Let us look at this sample for example. We can see that `r heights %>% filter((son >= confidence_adult$conf.int[1]) & (son <= confidence_adult$conf.int[2])) %>% nrow()` out of `r nrow(heights)` observations are within the confidence interval. This just gives us proof that we should not be overly confident that sample one additional observation will necessarily be within a confidence interval.

## Part B

Here we are going to find some important summary statistics.

### Part i

Finding $\bar{y}$. This is the son average height.
```{r problem 1 part b part i}
y_bar <- mean(heights$son)
y_bar
```
Here we can see that the $\bar{y}$ = `r y_bar` inches.

### Part ii

Finding $\bar{x}$. This is the midparent average height.
```{r problem 1 part b part ii}
x_bar <- mean(heights$parent)
x_bar
```
Here we can see that the $\bar{x}$ = `r x_bar` inches.

### Part iii

Finding $S_{xy}$.
```{r problem 1 part b part iii}
S_xy <- sum((heights$parent - x_bar) * (heights$son - y_bar))
S_xy
```
Here we can see that $S_{xy}$ is `r S_xy`.

### Part iv

Finding $s_{xy}$.
```{r problem 1 part b part iv}
s_xy <- (1 / (nrow(heights) - 1)) * sum((heights$parent - x_bar) * (heights$son - y_bar))
s_xy
```
Here we can see that $s_{xy}$ is `r s_xy`.

### Part v

Finding $\frac{1}{n-1}\sum{(x_i - \bar{x})y_i}$
```{r problem 1 part b part v}
sum_v <- (1 / (nrow(heights) - 1)) * sum((heights$parent - x_bar) * heights$son)
sum_v
```
We can find this value to be `r sum_v`.

### Part vi

Finding $\frac{1}{n-1}\sum{x_i(y_i - \bar{y})}$
```{r problem 1 part b part vi}
sum_vi <- (1 / (nrow(heights) - 1)) * sum((heights$son - y_bar) * heights$parent)
sum_vi
```
We can find this value to be `r sum_vi`.

### Part vii

Finding $S_{xx}$
```{r problem 1 part b part vii}
S_xx <- sum((heights$parent - x_bar) ** 2)
S_xx
```
Here we can see that $S_{xx}$ is `r S_xx`.

### Part viii

Finding $s_{x}^2$
```{r problem 1 part b part viii}
s_x2 <- (1 / (nrow(heights) - 1)) * sum((heights$parent - x_bar) ** 2)
s_x2
```
Here we can see that $s_{x}^2$ is `r s_x2`.

### Part ix

Finding $S_{yy}$
```{r problem 1 part b part ix}
S_yy <- sum((heights$son - y_bar) ** 2)
S_yy
```
Here we can see that $S_{yy}$ is `r S_yy`.

### Part x

Finding $s_{y}^2$
```{r problem 1 part b part x}
s_y2 <- (1 / (nrow(heights) - 1)) * sum((heights$son - y_bar) ** 2)
s_y2
```
Here we can see that $s_{y}^2$ is `r s_y2`.

### Part xi

Finding $r$. In this case, the equation we are using to find $r$ is $r = \frac{S_{xy}}{\sqrt{S_{xx}S_{xy}}}$
```{r problem 1 part b part xi}
r <- S_xy / (sqrt(S_xx * S_xy))
r
```
Here we can see the $r$ value is `r r`

## Part C

We are going to find the slope using $r$, $s_x$, and $s_y$. We will call the slope, b. The equation to find b is $b = r * \frac{s_y}{s_x}$. Note we have $s_x^2$ and $s_y^2$ so we will have to take the square roots of these values to use them in the equation.
```{r problem 1 part c}
slope <- r * (sqrt(s_y2) / sqrt(s_x2))
slope
```
Here we can see that with our x variable being midparent's height and our y variable is son's height that our slope is `r slope`.

# Problem 2

When solving parts we are going to use the following information:

- Pre-treatment is the x variable and post-treatment is the y variable
- $r$ = 0.7
- $\bar{x}$ = 10.7
- $\bar{y}$ = 7.9
- $s_x$ = 4.8
- $s_y$ = 6.7
- $n$ = 30

## Part A

Obtain a 95% confidence interval for the mean of the population from which the sample was drawn, post-treatment. The formula we will use is confidence interval = $\bar{y} \pm z * \frac{s_y}{\sqrt{n}}$ where $z = 1.96$ in a 95% confidence interval
```{r problem 2 part a}
r_treatment <- 0.7
x_bar_treatment <- 10.7
y_bar_treatment <- 7.9
s_x_treatment <- 4.8
s_y_treatment <- 6.7
n_treatment <- 30
z_95 <- 1.96
post_treat_confidence_interval_lower <- y_bar_treatment - z_95 * (s_y_treatment / sqrt(n_treatment))
post_treat_confidence_interval_lower
post_treat_confidence_interval_upper <- y_bar_treatment + z_95 * (s_y_treatment / sqrt(n_treatment))
post_treat_confidence_interval_upper
```
We are also 95% confident that the mean count of the bacteria from post-treatment is between `r post_treat_confidence_interval_lower` and `r post_treat_confidence_interval_upper`.

## Part B

Obtain the least squares estimates of the slope and intercept in a linear regression model in which the mean of Y is linear in x. Please note that we can find the slope of a regression line by $b = r * \frac{s_y}{s_x}$. The intercept can be found by $a = \bar{y} - b * \bar{x}$
```{r problem 2 part b}
slope_treatment <- r_treatment * (s_y_treatment / s_x_treatment)
slope_treatment
intercept_treatment <- y_bar_treatment - (slope_treatment * x_bar_treatment)
intercept_treatment
```

We get a regression line that we analyze the pre-treatment and post-treatment bacteria counts by saying that the predicted bacteria count post_treatment = `r intercept_treatment` + `r slope_treatment` * pre-treatment bacteria count. Also known as $\hat{y}$ = `r intercept_treatment` + `r slope_treatment` * x.

## Part C

Use the regression line to estimate mean post-treatment score among those with average pre-treatment levels of the bacteria (x = $\bar{x}$).
```{r problem 2 part c}
average_post <- intercept_treatment + slope_treatment * x_bar_treatment
average_post
```
Using our regression line, we would expect the post-treatment bacteria count to be `r average_post` if the pre-treatment bacteria count is the average amount of `r x_bar_treatment` (when x = $\bar{x}$).

## Part D

Estimate the standard error of the estimate in part(c). Since we are predicting the y values from x, we should use the formula: Standard Error = $\sqrt{\frac{MSE}{n}}$. Now MSE = $\frac{SSE}{n-2}$ and SSE = $\frac{s_y^2 * (n-1)}{\sqrt{1-r^2}}$. We are showing all of this below.
```{r problem 2 part d}
sum_of_squares_error_treatment <- ((s_y_treatment ** 2) * (n_treatment - 1)) * sqrt(1 - r_treatment ** 2)
mean_square_error_treatment <- sum_of_squares_error_treatment / (n_treatment - 2)
standard_error_treatment <- sqrt(mean_square_error_treatment / n_treatment)
standard_error_treatment
```
We can see here that the standard error of our estimate is `r standard_error_treatment`.

## Part E

Estimate the standard deviation of the estimate in part(c). Since we are predicting the y values from x, we should use the formula: Standard Deviation = standard error * $\sqrt{n}$.
```{r problem 2 part e}
standard_deviation_treatment <- standard_error_treatment * sqrt(n_treatment)
standard_deviation_treatment
```
We can see here that the standard deviation of our estimate is `r standard_deviation_treatment`.

## Part F

Here we can see that there is a difference between the standard error and the standard deviation. The standard error is equal to the standard deviation divided by the square root of n (or known as the sample size). Standard deviation tends to describe a single sample's variation between data points, while standard error describes multiple samples variability that come from the population. We can also say that standard deviation assesses how far a data point likely falls from the mean, while standard error assesses how far a sample statistic likely falls from a population parameter.

## Part G

Use the regression line to obtain 95% confidence limits for the mean post-treatment score among those with average pre-treatment levels of the bacteria (x = $\bar{x}$). Compare the width of this interval with that from part (a). Explain, briefly, how and why it is different.
```{r problem 2 part g}
t_treatment <- 2.048 # This is the t critical value with a 95% confidence interval with n-2 (or 30-2=28) degrees of freedom
lower_new_conf_interval <- y_bar_treatment - t_treatment * standard_error_treatment
lower_new_conf_interval
upper_new_conf_interval <- y_bar_treatment + t_treatment * standard_error_treatment
upper_new_conf_interval
```
We are 95% confident that the mean count of the bacteria from post-treatment is between `r lower_new_conf_interval` and `r upper_new_conf_interval`, using the least squares regression model to try to predict this. From part (a) 95% confident that the mean count of the bacteria from post-treatment is between `r post_treat_confidence_interval_lower` and `r post_treat_confidence_interval_upper`. We can see that by using regression, we have a narrower confidence interval and thus we now have a more precise estimate on the population parameter, which is the mean number of bacteria post-treatment.