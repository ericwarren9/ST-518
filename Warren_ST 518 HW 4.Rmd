---
title: "ST 518 Homework 4"
author: "Eric Warren"
date: "September 22, 2023"
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
options(scipen = 999)
```

```{r output setup, eval=FALSE, echo=FALSE}
# This code allows us to render a pdf document
rmarkdown::render("~/ST-518/Warren_ST 518 HW 4.Rmd", 
              output_format = "pdf_document", 
              output_options = list(
                toc = TRUE, 
                toc_depth = 3,
                number_sections = TRUE,
                df_print = "tibble"
                )
              )
```

# Problem 1

First we are going to read in the `battery` data and will show what it looks like. 
```{r read in battery}
library(tidyverse)
battery <- read_table("battery.txt")
battery$TypeBat <- factor(battery$TypeBat)
battery
```

## Part A

Write out the factorial effects model for the LPUC variable (lifetime per unit cost) that allows for the mean to vary across battery types. Include a random variable for an error term that has the same variance for all four battery types.

We know when the variances should be the same for all treatments groups that our model for One Factor Experiments should be $Y_{ij} = \mu + \tau_i + E_{ij}$ for $i = 1, 2, ..., t$ and $j = 1, 2, ..., n$ where $t$ is the number of treatments and $n$ is the sample size in each treatment. Also $E_{ij}$ are i.i.d $N(0, \sigma^2)$ errors. In this case, $t = 4$ and $n = 4$ given that there are 4 battery types and 4 batteries in each type. So knowing all of this our model should be written as $Y_{ij} = \mu + \tau_i + E_{ij}$ for $i = 1, 2, 3, 4$ and $j = 1, 2, 3, 4$ and $E_{ij}$ are i.i.d $N(0, \sigma^2)$ errors.

## Part B

Report the mean and variance for the 4 measurements from each of the four battery types.

We can do this by using the `group_by()` function in R to group all the data by battery type and then use the `summarize()` function to find the `mean` and `variance` of `LPUC` value by each battery type. I am assuming sample variance and sample mean in the question so our functions of `mean()` get the sample mean and `var()` get the sample variance.
```{r mean and variance of battery types}
mean_variance_output <- battery %>%
  group_by(TypeBat) %>%
  summarize(mean = mean(LPUC), variance = var(LPUC))
mean_variance_output
```

Here we can see the mean and variance of each battery type.

## Part C

Either by hand or using software, obtain the ANOVA table for your model. It should have three rows for Battery type, error and the corrected total sum of squares. 

Here we are going to use our `anova()` function to get an ANOVA table for battery types.
```{r anova battery types}
battery_model <- lm(LPUC ~ TypeBat, battery)
anova(battery_model)
```

This ANOVA table is basically complete. We just have to get the corrected total degrees of freedom and sum of squares. The degrees of freedom is just $n*t-1 = 4*4-1 = 15$ and this makes sense because the error degrees of freedom is `r anova(battery_model)$Df[[2]]` and the battery type degrees of freedom is `r anova(battery_model)$Df[[1]]` so added together is `r anova(battery_model)$Df[[1]] + anova(battery_model)$Df[[2]]`, which is what we expected. To get the Sum of Squares Total we add the Sum of Squares for `Battery Type` and the Sum of Squares for `Error`. The Sum of Squares for `Battery Type` is `r anova(battery_model)$"Sum Sq"[[1]]` and the Sum of Squares for `Error` is `r anova(battery_model)$"Sum Sq"[[2]]` so added together gets us `r anova(battery_model)$"Sum Sq"[[1]] + anova(battery_model)$"Sum Sq"[[2]]`, which is our Sum of Squares for `Corrected Total`. Thus, we have all the values we need for our final ANOVA table. 

|Source | DF | SS | MS | F-value | p-value
|----|:-----:|:-----:|:-----:|:------:|-----:|
|Battery Type | `r anova(battery_model)$Df[[1]]` | `r anova(battery_model)$"Sum Sq"[[1]]` | `r anova(battery_model)$"Mean Sq"[[1]]` | `r anova(battery_model)$"F value"[[1]]` | `r anova(battery_model)$"Pr(>F)"[[1]]` |
|Error | `r anova(battery_model)$Df[[2]]` | `r anova(battery_model)$"Sum Sq"[[2]]` | `r anova(battery_model)$"Mean Sq"[[2]]` | | |
|Corrected Total | `r anova(battery_model)$Df[[1]] + anova(battery_model)$Df[[2]]` | `r anova(battery_model)$"Sum Sq"[[1]] + anova(battery_model)$"Sum Sq"[[2]]` | | | |

## Part D

Two versions of the fitted model from PROC GLM, with parameter estimates $\hat{\mu}, \hat{\tau_1}, \hat{\tau_2}, \hat{\tau_3}, \hat{\tau_4}$  are
given. Use these models, say `fit1` and `fit2` to report estimates of each of the linear combinations of parameters below.

|Parameter | `fit1` | `fit2` |
|----|:-----:|-----:|
|$\theta_1 = \mu + \tau_1$ | $496.25+74.50 =$ `r 496.25+74.5`| $570.75 + 0=$ `r 570.75+0`|
|$\theta_2 = \tau_1$ | 74.50 | 0|
|$\theta_3 = \tau_1 - \tau_3$ | $-63.25-74.50=$ `r -63.25-74.5` | -137.75|
|$\theta_4 = \tau_3$ | -63.25 | -137.75|
|$\theta_5 = \mu + \tau_4$ | $496.25+0=$ `r 496.25+0` | $570.75+(-74.5)=$ `r 570.75+(-74.5)`|
|$\theta_6 = \mu + \frac{1}{4}\sum_{1}^{4} \tau_i$ | $496.25 + \frac{1}{4}*(74.5+364.25+(-63.25)+0)=$ `r 496.25 + (0.25 * (74.5+364.25+(-63.25)+0))`| $570.75 + \frac{1}{4}*(0+289.75+(-137.75)+(-74.5))=$ `r 570.75 + (0.25 * (0+289.75+(-137.75)+(-74.5)))`|
|$\theta_7 = \tau_2 - \tau_4$ | $364.25-0=$ `r 364.25-0`| $289.75-(-74.5)=$ `r 289.75-(-74.5)`|

## Part E

Which of the seven parameters considered in the table from **part (d)** are uniquely estimable? For each estimable parameter, give a linear combination of the data that has the parameter as its expectation. 

We have the following linear combinations that exist:
$$\begin{pmatrix} 1 & 1 & 0 & 0 & 0 \\ 1 & 0 & 1 & 0 & 0 \\ 1 & 0 & 0 & 1 & 0 \\ 1 & 0 & 0 & 0 & 1 \end{pmatrix}$$

Knowing this, we can look at all of them one by one to figure this out.

### Part i

We know that $\theta_1$ is estimable. This is because the linear combination of $(1, 1, 0, 0, 0)$ can be used to get this parameter expectation. 

### Part ii

We know that $\theta_2$ is **NOT** estimable. This is because the linear combination of $(0, 1, 0, 0, 0)$ has be used to get this parameter expectation and there is no way to manipulate the data linear combinations to get to the one we need for this.

### Part iii

We know that $\theta_3$ is an estimable. This is because the linear combination of $(0, 1, 0, -1, 0)$ can be used to get this parameter expectation. We can take the linear combination of $(1, 1, 0, 0, 0)$ minus the linear combination of $(1, 0, 0, 1, 0)$ to equal $(0, 1, 0, -1, 0)$.

### Part iv

We know that $\theta_4$ is **NOT** estimable. This is because the linear combination of $(0, 0, 0, 1, 0)$ has be used to get this parameter expectation and there is no way to manipulate the data linear combinations to get to the one we need for this.

### Part v

We know that $\theta_5$ is estimable. This is because the linear combination of $(1, 0, 0, 0, 1)$ can be used to get this parameter expectation. 

### Part vi

We know that $\theta_6$ is estimable. This is because the linear combination of $(1, \frac{1}{4}, \frac{1}{4}, \frac{1}{4}, \frac{1}{4})$ can be used to get this parameter expectation. We can get this by adding linear combination of $1, 1, 0, 0, 0)$ to $(1, 0, 1, 0, 0)$ to $(1, 0, 0, 1, 0)$ to $(1, 0, 0, 0, 1)$ to to get $(4, 1, 1, 1, 1)$. Then we can multiply the scalar of $\frac{1}{4}$ to get the linear combination of $\frac{1}{4}(4, 1, 1, 1, 1)$ to get $(1, \frac{1}{4}, \frac{1}{4},  \frac{1}{4},  \frac{1}{4})$. Thus, we have shown this estimable.

### Part vii

We know that $\theta_7$ is an estimable. This is because the linear combination of $(0, 0, 1, 0, -1)$ can be used to get this parameter expectation. We can take the linear combination of $(1, 0, 1, 0, 0)$ minus the linear combination of $(1, 0, 0, 0, 1)$ to equal $(0, 0, 1, 0, -1)$.

## Part F

Is $\theta_1$ a contrast? How about $\theta_3$?

We know that a contrast is when the $\sum_{1}^{t} c_j = 0$. 

From **part e**, we know that $\theta_1$ has the linear combination of $(1, 1, 0, 0, 0)$. Thus by taking the $\sum_{1}^{t} c_j = \sum_{1}^{4} c_j \neq 0$. We know this because all the values are non-negative (with $c_1 = 1$). So $\theta_1$ is not a contrast. 

From **part e**, we know that $\theta_3$ has the linear combination of $(0, 1, 0, -1, 0)$. Thus by taking the $\sum_{1}^{t} c_j = \sum_{1}^{4} c_j = 1 + 0 - 1 + 0 = 0$. So $\theta_3$ is a contrast.

## Part G

Compute the standard error of $\theta_3 = \bar{y_1} - \bar{y_3}$.

We know that the standard error of $\hat{\theta}$ is $\hat{SE\hat{\theta}} = \sqrt{MS(E) * \sum_{i=1}^{i=t} \frac{c_i^2}{n_i}}$. To find the standard error for $\theta_3$, we know from *part c* that the MS(E) is `r anova(battery_model)$"Mean Sq"[[2]]` and $n_i = 5$ for all $i = 1, 2, ..., t$. Now to find $\sum_{i=1}^{i=t} \frac{c_i^2}{n_i} = \frac{1^2}{4} + 0 + \frac{-1^2}{4} + 0 = \frac{1}{4} + \frac{1}{4} = \frac{1}{2}$. So, $\hat{SE\hat{\theta_3}} = \sqrt{MS(E) * \sum_{i=1}^{i=t} \frac{c_i^2}{n_i}} =$ (`r anova(battery_model)$"Mean Sq"[[2]]` * $\frac{1}{2}$) $^\frac{1}{2}$ = `r (anova(battery_model)$"Mean Sq"[[2]] * 0.5) ** 0.5`. So $\hat{SE(\hat{\theta_3})} =$ `r (anova(battery_model)$"Mean Sq"[[2]] * 0.5) ** 0.5`.

## Part H

Compute the contrast sum of squares for $\hat{\theta_3}$ and also for the least squares estimator of $\hat{\theta_3} = \bar{y_2} - \bar{y_4}$. Which contrast explains more of the battery type effect, $\hat{\theta_3}$ or $\hat{\theta_7}$?

We know that the $SS(\hat{\theta}) = \frac{\hat{\theta}^2}{\frac{c_1^2}{n_1} + ... + \frac{c_t^2}{n_t}}$ 

Some things we should note that we solved from *part b*:

- $\bar{y_1} =$ `r mean_variance_output$mean[1]`
- $\bar{y_2} =$ `r mean_variance_output$mean[2]`
- $\bar{y_3} =$ `r mean_variance_output$mean[3]`
- $\bar{y_4} =$ `r mean_variance_output$mean[4]`

So we know that $\hat{\theta_3} = \bar{y_1} - \bar{y_3} =$ `r mean_variance_output$mean[1] - mean_variance_output$mean[3]` and $\hat{\theta_7} = \bar{y_2} - \bar{y_4} =$ `r mean_variance_output$mean[2] - mean_variance_output$mean[4]`.

Now we can solve the sum of squares for both $\hat{\theta_3}$ and $\hat{\theta_7}$.

$SS(\hat{\theta_3}) = \frac{\hat{\theta_3}^2}{\frac{c_1^2}{n_1} + ... + \frac{c_t^2}{n_t}} =$ `r (mean_variance_output$mean[1] - mean_variance_output$mean[3])` $^2$ / $(\frac{1^2}{4} + 0 + \frac{-1^2}{4} + 0) =$ `r (mean_variance_output$mean[1] - mean_variance_output$mean[3]) ** 2` / $\frac{1}{2} =$ `r ((mean_variance_output$mean[1] - mean_variance_output$mean[3]) ** 2) / 0.5`. So $SS(\hat{\theta_3}) =$ `r ((mean_variance_output$mean[1] - mean_variance_output$mean[3]) ** 2) / 0.5`.

$SS(\hat{\theta_7}) = \frac{\hat{\theta_7}^2}{\frac{c_1^2}{n_1} + ... + \frac{c_t^2}{n_t}} =$ `r (mean_variance_output$mean[2] - mean_variance_output$mean[4])` $^2$ / $(0 + \frac{1^2}{4} + 0 + \frac{-1^2}{4}) =$ `r (mean_variance_output$mean[2] - mean_variance_output$mean[4]) ** 2` / $\frac{1}{2} =$ `r ((mean_variance_output$mean[2] - mean_variance_output$mean[4]) ** 2) / 0.5`. So $SS(\hat{\theta_7}) =$ `r ((mean_variance_output$mean[2] - mean_variance_output$mean[4]) ** 2) / 0.5`.

The higher sum of squares for $\hat{\theta_7}$ means that the contrast with $\hat{\theta_7}$ explains more of the battery type effect than $\hat{\theta_3}$.

## Part I

Are the contrasts $\theta_3$ and $\theta_7$ orthogonal? What is the covariance of the least squares estimators?

We know that contrasts are orthogonal if $\sum_{i=1}^{t} \frac{c_i*d_i}{n_i} = 0$ For $\theta_3$ the linear combination is (1, 0, -1, 0) and the for $\theta_7$ the linear combination is (0, 1, 0, -1). Therefore $\sum_{i=1}^{t} \frac{c_i*d_i}{n_i} = \frac{1*0}{n_1} + \frac{0*1}{n_2} + \frac{-1*0}{n_3} + \frac{0*-1}{n_4} = 0*0*0*0 = 0$ since $n_i \neq 0$ for $i = 1, 2, ..., t$. Therefore, $\theta_3$ and $\theta_7$ are orthogonal. Moreover, since they are orthogonal, their covariance is equal to 0 since orthogonal values are statistically uncorrelated and moreover independent if normally distributed. Therefore, $\theta_3$ and $\theta_7$ are orthogonal and have a covariance of 0.

# Problem 2

First we are going to read in the `tensile_strength` data and will show what it looks like. 
```{r read in tensile}
library(tidyverse)
tensile_strength <- read_table("tensile_strength.txt")
tensile_strength$CottonWtPer <- factor(tensile_strength$CottonWtPer)
tensile_strength
```

Let $Y_{ij}$ denote the observed tensile strength of unit j from cotton weight percentage level i for i, j = 1, . . . , 5. Consider a linear model for $Y_{ij}$ with factorial effects for cotton weight percentage.

## Part A

Report the sample mean, $\bar{y_i}$ and sample variance, $s_i^2$ for each level of cotton wt. percentage, i.

We can do this by using the `group_by()` function in R to group all the data by cotton weight and then use the `summarize()` function to find the `mean` and `variance` of `TensileStrength` value by each cotton weight type. I am assuming sample variance and sample mean in the question so our functions of `mean()` get the sample mean and `var()` get the sample variance.
```{r mean and variance of cotton weight types}
mean_variance_output2 <- tensile_strength %>%
  group_by(CottonWtPer) %>%
  summarize(sample_mean = mean(TensileStrength),
            sample_variance = var(TensileStrength))
mean_variance_output2
```

Here we found our sample mean and sample variance of the `tensile strength` for each cotton weight type.

## Part B

Write out a statistical model for $Y_{ij}$ which assumes the response varies normally about a weight specific mean, with constant variance. 

We know when the variances should be the same for all treatments groups that our model for One Factor Experiments should be $Y_{ij} = \mu + \tau_i + E_{ij}$ for $i = 1, 2, ..., t$ and $j = 1, 2, ..., n$ where $t$ is the number of treatments and $n$ is the sample size in each treatment. Also $E_{ij}$ are i.i.d $N(0, \sigma^2)$ errors. In this case, $t = 5$ and $n = 5$ given that there are 4 battery types and 4 batteries in each type. So knowing all of this our model should be written as $Y_{ij} = \mu + \tau_i + E_{ij}$ for $i = 1, 2, 3, 4, 5$ and $j = 1, 2, 3, 4, 5$ and $E_{ij}$ are i.i.d $N(0, \sigma^2)$ errors. 

## Part C

Report the fitted model of the form $\hat{Y_{ij}} = \hat{\mu} + \hat{\tau_i}$ and supply numerical estimates for all location parameters, or functions of location parameters, that would enable a user to predict a future observation for a give cotton weight percentage.

We should look at the values it takes by using the `summary()` function on our fitted model (which uses the `lm()` function). The code is below.
```{r fitted model for tensile strength}
tensile_strength_model <- lm(TensileStrength ~ CottonWtPer, tensile_strength)
summary(tensile_strength_model)
```

As we can see our model can be written out as $Y_i =$ `r tensile_strength_model$coefficients[[1]]` + `r tensile_strength_model$coefficients[[2]]` * $x_{2i}$ + `r tensile_strength_model$coefficients[[3]]` * $x_{3i}$ + `r tensile_strength_model$coefficients[[4]]` * $x_{4i}$ + `r tensile_strength_model$coefficients[[5]]` * $x_{5i}$ where $x_{ti}$ represents an indicator variable if the specific value matched up with the corresponding treatment $t$ (it is equal to 1 if it does match and 0 if it does not match). Note, $t = 1$ for cotton weight of 15, $t = 2$ for cotton weight of 20, $t = 3$ for cotton weight of 25, $t = 4$ for cotton weight of 30, and $t = 5$ for cotton weight of 35.

## Part D

Using level of significance $\alpha$ = .05, test the null hypothesis that mean tensile strength is constant across the levels of cotton weight percentage considered in this experiment. Provide all the elements of the test ($H_0$, critical value, observed value of the test statistic, conclusion).

Here we are going to say that our null hypothesis is that $H_0: \mu_1 = \mu_2 = \mu_3 = \mu_4 = \mu_5$. Our alternative hypothesis is that $H_A$: At least one of the $\mu_i$ terms from $i = 1, 2, 3, 4, 5$ does not equal the rest. We can do a F-test to look at this below.
```{r anova test on cotton}
anova(tensile_strength_model)
```

As we can see, we get a F-observed value of `r anova(tensile_strength_model)$"F value"[[1]]` with a numerator degrees of freedom (the `CottonWtPer` df) of `r anova(tensile_strength_model)$"Df"[[1]]` and a denominator degrees of freedom (the `Residuals` df) of `r anova(tensile_strength_model)$"Df"[[2]]`. Using our `qf()` function, we can put in our alpha level of 0.05, our numerator degrees of freedom, and our denominator degrees of freedom to get a F-critical value of `r qf(0.05, anova(tensile_strength_model)$"Df"[[1]], anova(tensile_strength_model)$"Df"[[2]], lower.tail = F)`. Since our F-observed value is `r ifelse(anova(tensile_strength_model)$"F value"[[1]] > qf(0.05, anova(tensile_strength_model)$"Df"[[1]], anova(tensile_strength_model)$"Df"[[2]], lower.tail = F), "greater than", "less than")` our F-critical value we should `r ifelse(anova(tensile_strength_model)$"F value"[[1]] > qf(0.05, anova(tensile_strength_model)$"Df"[[1]], anova(tensile_strength_model)$"Df"[[2]], lower.tail = F), "reject", "fail to reject")` our null hypothesis that $\mu_1 = \mu_2 = \mu_3 = \mu_4 = \mu_5$. Therefore, we `r ifelse(anova(tensile_strength_model)$"F value"[[1]] > qf(0.05, anova(tensile_strength_model)$"Df"[[1]], anova(tensile_strength_model)$"Df"[[2]], lower.tail = F), "have", "do not have")` statistically significant evidence to say that at least one of the $\mu_i$ values from $i = 1, 2, 3, 4, 5$ is different from the others. Moreover this means that the mean tensile strength `r ifelse(anova(tensile_strength_model)$"F value"[[1]] > qf(0.05, anova(tensile_strength_model)$"Df"[[1]], anova(tensile_strength_model)$"Df"[[2]], lower.tail = F), "is not", "can be")` constant for all cotton weight percentages considered.

## Part E

Provide an ANOVA table to accompany the analysis.

From *part d*, we saw a partial ANOVA, which is also shown below:
```{r anova test shown again on cotton}
anova(tensile_strength_model)
```

We will fill in the rest of the table by filling in the `Total` or also known as the `Corrected Total` section of the table. We need the degrees of freedom and Sum of Squares values. For degrees of freedom, we can get that by adding the `CottonWtPer` (which is `r anova(tensile_strength_model)$"Df"[[1]]`) and the `Residuals` (which is `r anova(tensile_strength_model)$"Df"[[2]]`). Therefore the `Corrected Total` degrees of freedom is `r anova(tensile_strength_model)$"Df"[[1]] + anova(tensile_strength_model)$"Df"[[2]]`. To get the sum of square value, we can also add the SS(`CottonWtPer`) with the SS(`Residual`). Note: SS(Total) = SS(Model) + SS(Error). Therefore we can see from our partial ANOVA table the SS(`CottonWtPer`) = `r anova(tensile_strength_model)$"Sum Sq"[[1]]` and the SS(`Residual`) = `r anova(tensile_strength_model)$"Sum Sq"[[2]]`. So adding them together we can get the SS(`Corrected Total`) = `r anova(tensile_strength_model)$"Sum Sq"[[1]] + anova(tensile_strength_model)$"Sum Sq"[[2]]`. Now we can fill in the rest of our table below with these values.

|Source | DF | SS | MS | F-value | p-value
|----|:-----:|:-----:|:-----:|:------:|-----:|
|Cotton Weight | `r anova(tensile_strength_model)$Df[[1]]` | `r anova(tensile_strength_model)$"Sum Sq"[[1]]` | `r anova(tensile_strength_model)$"Mean Sq"[[1]]` | `r anova(tensile_strength_model)$"F value"[[1]]` | `r anova(tensile_strength_model)$"Pr(>F)"[[1]]` |
|Error | `r anova(tensile_strength_model)$Df[[2]]` | `r anova(tensile_strength_model)$"Sum Sq"[[2]]` | `r anova(tensile_strength_model)$"Mean Sq"[[2]]` | | |
|Corrected Total | `r anova(tensile_strength_model)$Df[[1]] + anova(tensile_strength_model)$Df[[2]]` | `r anova(tensile_strength_model)$"Sum Sq"[[1]] + anova(tensile_strength_model)$"Sum Sq"[[2]]` | | | |

## Part F

What proportion of variability in tensile strength is explained by Cotton Weight Percentage?

We know to find the proportion of variability we need to find the $R^2$ value. To do this, we can use a formula we learned that $R^2 = \frac{SS(R)}{SS(Tot)}$. Note, from *part e*, we found that the SS(Tot) = `r anova(tensile_strength_model)$"Sum Sq"[[1]] + anova(tensile_strength_model)$"Sum Sq"[[2]]` and the SS(R) = `r anova(tensile_strength_model)$"Sum Sq"[[1]]`. Therefore, $R^2 = \frac{SS(R)}{SS(Tot)} =$ `r anova(tensile_strength_model)$"Sum Sq"[[1]]` / `r anova(tensile_strength_model)$"Sum Sq"[[1]] + anova(tensile_strength_model)$"Sum Sq"[[2]]` = `r anova(tensile_strength_model)$"Sum Sq"[[1]] / (anova(tensile_strength_model)$"Sum Sq"[[1]] + anova(tensile_strength_model)$"Sum Sq"[[2]])`. Therefore, we can say that `r 100 *  anova(tensile_strength_model)$"Sum Sq"[[1]] / (anova(tensile_strength_model)$"Sum Sq"[[1]] + anova(tensile_strength_model)$"Sum Sq"[[2]])`% of the variability in tensile strength is explained by Cotton Weight Percentage.

## Part G

Consider a linear contrast among the five treatment means,
$$\hat{\theta_L} = -2\bar{y_1}-\bar{y_2}+\bar{y_4}+2\bar{y_5}$$

If $\mu_i$ denotes the population mean of units treated with cotton weight percentage $i$ and the vector $\mu$ is defined by $\mu$ = ($\mu_1$, $\mu_2$, $\mu_3$, $\mu_4$, $\mu_5$)' then 
$$\hat{\theta_L} = (-2, -1, 0, 1, 2) \mu$$

### Part i

Compute $\hat{\theta_L}$.

We know that $\hat{\theta_L} = -2\bar{y_1}-\bar{y_2}+\bar{y_4}+2\bar{y_5}$. From *part a* we know that,

- $\bar{y_1} =$ `r mean_variance_output2$sample_mean[[1]]`
- $\bar{y_2} =$ `r mean_variance_output2$sample_mean[[2]]`
- $\bar{y_4} =$ `r mean_variance_output2$sample_mean[[4]]`
- $\bar{y_5} =$ `r mean_variance_output2$sample_mean[[5]]`

Therefore, $\hat{\theta_L} = -2\bar{y_1}-\bar{y_2}+\bar{y_4}+2\bar{y_5} =$ -2 x `r mean_variance_output2$sample_mean[[1]]` - `r mean_variance_output2$sample_mean[[2]]` + `r mean_variance_output2$sample_mean[[4]]` + 2 x `r mean_variance_output2$sample_mean[[5]]` = `r -2 * mean_variance_output2$sample_mean[[1]] - mean_variance_output2$sample_mean[[2]] + mean_variance_output2$sample_mean[[4]] + 2 * mean_variance_output2$sample_mean[[5]]`. So, $\hat{\theta_L} =$ `r -2 * mean_variance_output2$sample_mean[[1]] - mean_variance_output2$sample_mean[[2]] + mean_variance_output2$sample_mean[[4]] + 2 * mean_variance_output2$sample_mean[[5]]`.

### Part ii

Report the standard error for the estimated contrast in part (i), $\hat{SE(\hat{\theta_L})}$.

We know that $\hat{SE(\hat{\theta_L})} = \sqrt{MS(E) * \sum_{i=1}^{i=t} \frac{c_i^2}{n_i}}$. To find the standard error for $\hat{\theta_L}$, we know from *part e* that the MS(E) is `r anova(tensile_strength_model)$"Mean Sq"[[2]]` and $n_i = 5$ for all $i = 1, 2, ..., t$. Now to find $\sum_{i=1}^{i=t} \frac{c_i^2}{n_i} = \frac{-2^2}{5} + \frac{-1^2}{5} + 0 + \frac{1^2}{5} + \frac{2^2}{5} = \frac{4}{5} + \frac{1}{5} + \frac{1}{5} + \frac{4}{5} = 2$. So, $\hat{SE(\hat{\theta_L})} = \sqrt{MS(E) * \sum_{i=1}^{i=t} \frac{c_i^2}{n_i}} =$ (`r anova(tensile_strength_model)$"Mean Sq"[[2]]` * $2$) $^\frac{1}{2}$ = `r (anova(tensile_strength_model)$"Mean Sq"[[2]] * 2) ** 0.5`. So $\hat{SE(\hat{\theta_L})} =$ `r (anova(tensile_strength_model)$"Mean Sq"[[2]] * 2) ** 0.5`.

### Part iii

Report the sum of squares associated with the contrast i part (i). Of the variability among the five observed treatment means, what proportion is explained by this contrast? Note that sums of squares are used to quantify observed variability.

We know that the $SS(\hat{\theta_L}) = \frac{\hat{\theta_L}^2}{\frac{c_1^2}{n_1} + ... + \frac{c_t^2}{n_t}}$. We also know from before that:

- $c_1 = -2$ From information about *part g*
- $c_2 = -1$ From information about *part g*
- $c_3 = 0$ From information about *part g*
- $c_4 = 1$ From information about *part g*
- $c_5 = 2$ From information about *part g*
- $n_i = 5$ for $i = 1, 2, ..., t$ From *part g part ii*
- $\frac{c_1^2}{n_1} + ... + \frac{c_t^2}{n_t} = 2$
- $\hat{\theta_L} =$ `r -2 * mean_variance_output2$sample_mean[[1]] - mean_variance_output2$sample_mean[[2]] + mean_variance_output2$sample_mean[[4]] + 2 * mean_variance_output2$sample_mean[[5]]` From *part g part i*

So to plug it all in we know that $SS(\hat{\theta_L}) = \frac{\hat{\theta_L}^2}{\frac{c_1^2}{n_1} + ... + \frac{c_t^2}{n_t}} =$ `r (-2 * mean_variance_output2$sample_mean[[1]] - mean_variance_output2$sample_mean[[2]] + mean_variance_output2$sample_mean[[4]] + 2 * mean_variance_output2$sample_mean[[5]])` $^2$ / 2 = `r (-2 * mean_variance_output2$sample_mean[[1]] - mean_variance_output2$sample_mean[[2]] + mean_variance_output2$sample_mean[[4]] + 2 * mean_variance_output2$sample_mean[[5]]) ** 2 / 2`. So $SS(\hat{\theta_L}) =$ `r (-2 * mean_variance_output2$sample_mean[[1]] - mean_variance_output2$sample_mean[[2]] + mean_variance_output2$sample_mean[[4]] + 2 * mean_variance_output2$sample_mean[[5]]) ** 2 / 2`.

We know to find the proportion of variability we need to find the $R^2$ value. To do this, we can use a formula we learned that Variability among 5 treatment means $= \frac{SS(\hat{\theta_L})}{SS(R)}$. Note, from *part e*, we found that the SS(R) = `r anova(tensile_strength_model)$"Sum Sq"[[1]]` and the SS($\hat{\theta_L}$) = `r (-2 * mean_variance_output2$sample_mean[[1]] - mean_variance_output2$sample_mean[[2]] + mean_variance_output2$sample_mean[[4]] + 2 * mean_variance_output2$sample_mean[[5]]) ** 2 / 2`. Thus this variability explained $= \frac{SS(R)}{SS(R)} =$ `r (-2 * mean_variance_output2$sample_mean[[1]] - mean_variance_output2$sample_mean[[2]] + mean_variance_output2$sample_mean[[4]] + 2 * mean_variance_output2$sample_mean[[5]]) ** 2 / 2` / `r anova(tensile_strength_model)$"Sum Sq"[[1]]` = `r ((-2 * mean_variance_output2$sample_mean[[1]] - mean_variance_output2$sample_mean[[2]] + mean_variance_output2$sample_mean[[4]] + 2 * mean_variance_output2$sample_mean[[5]]) ** 2 / 2) / (anova(tensile_strength_model)$"Sum Sq"[[1]])`. Therefore, we can say that `r 100 *  ((-2 * mean_variance_output2$sample_mean[[1]] - mean_variance_output2$sample_mean[[2]] + mean_variance_output2$sample_mean[[4]] + 2 * mean_variance_output2$sample_mean[[5]]) ** 2 / 2) / (anova(tensile_strength_model)$"Sum Sq"[[1]])`% of the variability among the five observed treatment means is explained by this contrast.

### Part iv

Is too much cotton weight a bad thing? Before conducting any kind of test, do you see, from the table or from a plot of the means, evidence of non-linearity? Explain briefly. Then, using $\alpha = 0.05$, conduct a lack-of-fit for model in which mean tensile strength is a linear function of cotton weight percentage.

First we are going to plot what the data looks like to see if we can see any kind of trend.
```{r plotting cotton data}
ggplot(data = tensile_strength, aes(x = CottonWtPer, y = TensileStrength)) +
  geom_point(aes(color = CottonWtPer), position = "jitter") + 
  labs(x = "Cotton Weight",
       y = "Tensile Strength",
       title = "How Cotton Weight Affects the Tensile Strength",
       color = "Cotton Weight",
       caption = "Eric Warren") + 
  theme_bw()
```

As we can see, there seems to be an increase in strength until we get to the cotton weight of 30 (where it peaks) and then it seems to fall rapidly in strength. From this alone, there seems to be a point where too much cotton weight is a bad thing, as strength seems to be a quadratic trend. To back up this claim we will need to do a lack of fit test. Our null hypothesis $H_0:$ The Factorial Effects Model can be demonstrated by a Simple Linear Regression Model and our alternative hypothesis $H_A:$ The Factorial Effects Model *cannot* be demonstrated by a Simple Linear Regression Model. First, we should look at the simple linear regression model.
```{r slr on cotton}
# Convert back to numeric before modeling
tensile_strength2 <- tensile_strength
tensile_strength2$CottonWtPer <- as.numeric(tensile_strength2$CottonWtPer)

# Make SLR model
tensile_strength_slr_model <- lm(TensileStrength ~ CottonWtPer, tensile_strength2)

# Print the summary of the model
summary(tensile_strength_slr_model)

# Print the anova table of model
anova(tensile_strength_slr_model)
```

As we can see here our SS($R_{poly}$) = `r anova(tensile_strength_slr_model)$"Sum Sq"[[1]]` and our SS($E_{poly}$) = `r anova(tensile_strength_slr_model)$"Sum Sq"[[2]]`. Now this will help us get our F-statistic which can be calculated by $F = \frac{SS(Lack of Fit) / (t-1-p)}{MS(Pure Error)}$. Now it is time to get all the parts and plug it in to get our F-statistic.

- We know $MS(Pure Error) = MS(E_{full})$. From *part e*, we showed that $MS(E_{full}) =$ `r anova(tensile_strength_model)$"Mean Sq"[[2]]`.
- We know that $t-1-p = t-1-1 = 5-1-1 = 3$. We know from the general description of *Problem 2* that there are 5 treatment groups so $t = 5$. We also know $p = 1$ because our lack of fit test is using a simple linear regression model as a comparison which means the number of predictors in that model is $p = 1$. So $t-1-p = 3$.
- We know that $SS(Lack of Fit) = SS(Trt) - SS(R_{poly})$. From this part, we showed that SS($R_{poly}$) = `r anova(tensile_strength_slr_model)$"Sum Sq"[[1]]`. To find SS($Trt$), we can look back at *part e* in our ANOVA table to see that this is equal to `r anova(tensile_strength_model)$"Sum Sq"[[1]]`. So $SS(Trt) =$ `r anova(tensile_strength_model)$"Sum Sq"[[1]]`. Therefore, we can now show that $SS(Lack of Fit) = SS(Trt) - SS(R_{poly}) =$ `r anova(tensile_strength_model)$"Sum Sq"[[1]] - anova(tensile_strength_slr_model)$"Sum Sq"[[1]]`. So $SS(Lack of Fit) =$ `r anova(tensile_strength_model)$"Sum Sq"[[1]] - anova(tensile_strength_slr_model)$"Sum Sq"[[1]]`.

Now we can get our F-statistic which is $F = \frac{SS(Lack of Fit) / (t-1-p)}{MS(Pure Error)} =$ (`r anova(tensile_strength_model)$"Sum Sq"[[1]] - anova(tensile_strength_slr_model)$"Sum Sq"[[1]]` / 3) / `r anova(tensile_strength_model)$"Mean Sq"[[2]]` = `r ((anova(tensile_strength_model)$"Sum Sq"[[1]] - anova(tensile_strength_slr_model)$"Sum Sq"[[1]]) / 3) / (anova(tensile_strength_model)$"Mean Sq"[[2]])`. So with our F-statistic of `r ((anova(tensile_strength_model)$"Sum Sq"[[1]] - anova(tensile_strength_slr_model)$"Sum Sq"[[1]]) / 3) / (anova(tensile_strength_model)$"Mean Sq"[[2]])`, we need to compare this with our F-critical value. This can be found by using F($\alpha$, numerator degrees of freedom, denominator degrees of freedom). We were told that $\alpha = 0.05$, the numerator degrees of freedom = 3 (which is just $t-1-p$), and our denominator degrees of freedom = 20 (the same as our Error degrees of freedom from the full one-factor model). So using our `qf()` function in R to get the F-critical value we should get `F(0.05, 3, 20)` = `r qf(0.05, 3, 20, lower.tail = F)`. 

Since our F-observed value is `r ifelse(((anova(tensile_strength_model)$"Sum Sq"[[1]] - anova(tensile_strength_slr_model)$"Sum Sq"[[1]]) / 3) / (anova(tensile_strength_model)$"Mean Sq"[[2]]) > qf(0.05, anova(tensile_strength_model)$"Df"[[1]] - 1, anova(tensile_strength_model)$"Df"[[2]], lower.tail = F), "greater than", "less than")` our F-critical value we should `r ifelse(((anova(tensile_strength_model)$"Sum Sq"[[1]] - anova(tensile_strength_slr_model)$"Sum Sq"[[1]]) / 3) / (anova(tensile_strength_model)$"Mean Sq"[[2]]) > qf(0.05, anova(tensile_strength_model)$"Df"[[1]] - 1, anova(tensile_strength_model)$"Df"[[2]], lower.tail = F), "reject", "fail to reject")` our null hypothesis that the Factorial Effects Model can be demonstrated by a Simple Linear Regression Model. Therefore, we `r ifelse(((anova(tensile_strength_model)$"Sum Sq"[[1]] - anova(tensile_strength_slr_model)$"Sum Sq"[[1]]) / 3) / (anova(tensile_strength_model)$"Mean Sq"[[2]]) > qf(0.05, anova(tensile_strength_model)$"Df"[[1]] - 1, anova(tensile_strength_model)$"Df"[[2]], lower.tail = F), "have", "do not have")` statistically significant evidence to say that the Factorial Effects Model *cannot* be demonstrated by a Simple Linear Regression Model. Moreover this means that we `r ifelse(((anova(tensile_strength_model)$"Sum Sq"[[1]] - anova(tensile_strength_slr_model)$"Sum Sq"[[1]]) / 3) / (anova(tensile_strength_model)$"Mean Sq"[[2]]) > qf(0.05, anova(tensile_strength_model)$"Df"[[1]] - 1, anova(tensile_strength_model)$"Df"[[2]], lower.tail = F), "cannot", "can")` consider a simple linear regression model to predict the tensile strength from the cotton weight (as this relationship is not linear).